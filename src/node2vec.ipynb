{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8-pLJIUJd8_"
      },
      "outputs": [],
      "source": [
        "!pip install node2vec\n",
        "\n",
        "import networkx as nx\n",
        "from node2vec import Node2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import requests\n",
        "import gzip\n",
        "import shutil\n",
        "from networkx.algorithms.community import modularity\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "P_RETURN = 2\n",
        "Q_IN_OUT = 1\n",
        "DIMENSIONS = 64\n",
        "WALK_LENGTH = 30\n",
        "NUM_WALKS = 10\n",
        "NUM_CLUSTERS = 10  # k=10 for k-means\n",
        "\n",
        "DATASET_URL = \"https://snap.stanford.edu/data/facebook_combined.txt.gz\"\n",
        "DATASET_PATH = 'facebook_combined.txt'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_dataset():\n",
        "    if os.path.exists(DATASET_PATH):\n",
        "        return\n",
        "\n",
        "    response = requests.get(DATASET_URL, stream=True)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        compressed_file = \"twitter_combined.txt.gz\"\n",
        "        with open(compressed_file, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        with gzip.open(compressed_file, 'rb') as f_in:\n",
        "            with open(DATASET_PATH, 'wb') as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "        os.remove(compressed_file)\n",
        "        print(\"Download complete\")\n",
        "    else:\n",
        "        print(f\"failed to download, {response.status_code}\")\n",
        "        raise Exception(\"Download failed\")\n",
        "\n",
        "download_dataset()"
      ],
      "metadata": {
        "id": "VB3_lsH4JiLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_graph(filepath):\n",
        "    G = nx.read_edgelist(filepath, create_using=nx.Graph(), nodetype=int)\n",
        "    print(f\"Graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "    return G\n",
        "\n",
        "graph = load_graph(DATASET_PATH)"
      ],
      "metadata": {
        "id": "d_7iIWaJJxRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(G):\n",
        "    \"\"\"\n",
        "    Trains the Node2Vec model using the established hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # use disk storage to prevent ram crash\n",
        "    temp_dir = \"./node2vec_temp\"\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    node2vec = Node2Vec(\n",
        "        G,\n",
        "        dimensions=DIMENSIONS,\n",
        "        walk_length=WALK_LENGTH,\n",
        "        num_walks=NUM_WALKS,\n",
        "        p=P_RETURN,\n",
        "        q=Q_IN_OUT,\n",
        "        workers=4,\n",
        "        temp_folder=temp_dir,\n",
        "        quiet=False\n",
        "    )\n",
        "\n",
        "    print(f\"Pre-computation took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    print(\"Training model on random walks...\")\n",
        "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = train_model(graph)"
      ],
      "metadata": {
        "id": "_jzwp5d3J06n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"twitter_embeddings_d64_p2_q1.emb\"\n",
        "model.wv.save_word2vec_format(filename)\n",
        "print(f\"Embeddings saved as {filename}\")\n"
      ],
      "metadata": {
        "id": "dQ3DmRyjJ4vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_embeddings(model):\n",
        "    nodes = list(model.wv.index_to_key)\n",
        "    vectors = [model.wv[node] for node in nodes]\n",
        "\n",
        "    kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42)\n",
        "    kmeans.fit(vectors)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    return dict(zip(nodes, labels))\n",
        "\n",
        "communities = cluster_embeddings(model)\n",
        "print(\"Clustering complete:\", list(communities.items())[:5])"
      ],
      "metadata": {
        "id": "ffD8hcASJ7a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(G, communities_dict, top_n=10, k=100):\n",
        "\n",
        "\n",
        "    community_sets = {}\n",
        "\n",
        "    first_graph_node = next(iter(G.nodes()))\n",
        "    convert_to_int = isinstance(first_graph_node, int)\n",
        "    # 1. modularity calculation\n",
        "    for node_id, label in communities_dict.items():\n",
        "        try:\n",
        "            node = int(node_id) if convert_to_int else node_id\n",
        "        except ValueError:\n",
        "            continue\n",
        "        if node in G:\n",
        "            if label not in community_sets:\n",
        "                community_sets[label] = set()\n",
        "            community_sets[label].add(node)\n",
        "\n",
        "    valid_nodes = set().union(*community_sets.values())\n",
        "    G_sub = G.subgraph(valid_nodes)\n",
        "\n",
        "    if len(G_sub) > 0:\n",
        "        mod_score = modularity(G_sub, list(community_sets.values()))\n",
        "        print(f\"Modularity Score: {mod_score:.4f}\")\n",
        "    else:\n",
        "        print(\"Modularity Score Error\")\n",
        "\n",
        "    # 2. betweenness centrality calculation\n",
        "\n",
        "    centrality = nx.betweenness_centrality(G, k=k, normalized=True, seed=42)\n",
        "\n",
        "    top_nodes = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "\n",
        "    print(f\"Top {top_n} Influencers:\")\n",
        "    print(f\"{'Rank':<5} | {'Node ID':<15} | {'Score'}\")\n",
        "    print(\"-\" * 40)\n",
        "    for i, (node, score) in enumerate(top_nodes, 1):\n",
        "        print(f\"{i:<5} | {str(node):<15} | {score:.6f}\")\n",
        "\n",
        "calculate_metrics(graph, communities, k=100)"
      ],
      "metadata": {
        "id": "wzuLVLI0cr0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_embeddings(model, communities, num_nodes_to_plot=10000):\n",
        "    all_nodes = list(model.wv.index_to_key)\n",
        "    if len(all_nodes) > num_nodes_to_plot:\n",
        "        sampled_nodes = np.random.choice(all_nodes, num_nodes_to_plot, replace=False)\n",
        "    else:\n",
        "        sampled_nodes = all_nodes\n",
        "\n",
        "    vectors = np.array([model.wv[node] for node in sampled_nodes])\n",
        "    labels = [communities[node] for node in sampled_nodes]\n",
        "\n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "    embeddings_2d = tsne.fit_transform(vectors)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    scatter = plt.scatter(\n",
        "        embeddings_2d[:, 0],\n",
        "        embeddings_2d[:, 1],\n",
        "        c=labels,\n",
        "        cmap='viridis',\n",
        "        alpha=0.6,\n",
        "        s=10\n",
        "    )\n",
        "    plt.colorbar(scatter, label='Community Label')\n",
        "    plt.title(\"t-SNE Visualization of Facebook Ego Network (Node2Vec)\")\n",
        "    plt.xlabel(\"t-SNE Dimension 1\")\n",
        "    plt.ylabel(\"t-SNE Dimension 2\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_embeddings(model, communities)"
      ],
      "metadata": {
        "id": "48Wen57NcqEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PaJEgNJIoXif"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}